{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dermatologist-AI Project: Single Network Approach\n",
    "Workbook for a single network approach that classifies images into melanomas, nevus, or SBK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up and process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files       \n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from keras.preprocessing import image                  \n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "from tqdm import tqdm\n",
    "from PIL import ImageFile                            \n",
    "import os\n",
    "import pickle\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True      \n",
    "\n",
    "\n",
    "# define function to load train, test, and validation datasets\n",
    "def load_dataset(path, shuffle):\n",
    "    data = load_files(path, shuffle=shuffle)\n",
    "    file_paths = np.array(data['filenames'])\n",
    "    one_hot_labels = np_utils.to_categorical(np.array(data['target']),3)\n",
    "    return file_paths, one_hot_labels\n",
    "\n",
    "# define functions to convert images into 4D tensors for convnets\n",
    "def path_to_tensor(img_path):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    x = preprocess_input(x)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors) \n",
    "\n",
    "# define function to decide whether to load tensors from a saved pickle or raw images\n",
    "def load_tensors_and_labels(pickle_file, raw_file_path, shuffle, force=False):\n",
    "    pickle_file = os.path.join('.', pickle_file)\n",
    " \n",
    "    if force or not os.path.exists(pickle_file):\n",
    "        files, labels = load_dataset(raw_file_path, shuffle)\n",
    "        tensors = paths_to_tensor(files).astype('float32')/255\n",
    "        with open(pickle_file, 'wb') as handle:\n",
    "            pickle.dump([tensors, labels], handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        return tensors, labels\n",
    "\n",
    "    else:        \n",
    "        with open(pickle_file, 'rb') as handle:\n",
    "            tensors, labels = pickle.load(handle)        \n",
    "        return tensors, labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2000/2000 [03:53<00:00,  8.57it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 150/150 [00:33<00:00,  4.46it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 600/600 [03:19<00:00, 11.11it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "\n",
    "train_tensors, train_labels = load_tensors_and_labels('train_data.pickle','../data/train', True)\n",
    "valid_tensors, valid_labels = load_tensors_and_labels('valid_data.pickle','../data/valid', True)\n",
    "test_tensors, test_labels = load_tensors_and_labels('test_data.pickle','../data/test', False)\n",
    "\n",
    "# load list of skin condition names\n",
    "skin_names = [item[14:-1] for item in sorted(glob(\"../data/train/*/\"))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network based on four three layers of VGG19 followed by trainable convnet and dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 256)               6422784   \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 21,760,835\n",
      "Trainable params: 11,175,683\n",
      "Non-trainable params: 10,585,152\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#First 4 blocks of VGG19\n",
    "model.add(Conv2D(filters=64, kernel_size=3, padding='same', activation='relu', trainable=False, name='block1_conv1', \n",
    "                        input_shape=(224, 224, 3)))\n",
    "model.add(Conv2D(filters=64, kernel_size=3, padding='same', activation='relu', trainable=False, name='block1_conv2'))\n",
    "model.add(MaxPooling2D(pool_size=2, name='block1_pool'))\n",
    "model.add(Conv2D(filters=128, kernel_size=3, padding='same', activation='relu', trainable=False, name='block2_conv1'))\n",
    "model.add(Conv2D(filters=128, kernel_size=3, padding='same', activation='relu', trainable=False, name='block2_conv2'))\n",
    "model.add(MaxPooling2D(pool_size=2, name='block2_pool'))\n",
    "model.add(Conv2D(filters=256, kernel_size=3, padding='same', activation='relu', trainable=False, name='block3_conv1'))\n",
    "model.add(Conv2D(filters=256, kernel_size=3, padding='same', activation='relu', trainable=False, name='block3_conv2'))\n",
    "model.add(Conv2D(filters=256, kernel_size=3, padding='same', activation='relu', trainable=False, name='block3_conv3'))\n",
    "model.add(Conv2D(filters=256, kernel_size=3, padding='same', activation='relu', trainable=False, name='block3_conv4'))\n",
    "model.add(MaxPooling2D(pool_size=2, name='block3_pool'))\n",
    "model.add(Conv2D(filters=512, kernel_size=3, padding='same', activation='relu', trainable=False, name='block4_conv1'))\n",
    "model.add(Conv2D(filters=512, kernel_size=3, padding='same', activation='relu', trainable=False, name='block4_conv2'))\n",
    "model.add(Conv2D(filters=512, kernel_size=3, padding='same', activation='relu', trainable=False, name='block4_conv3'))\n",
    "model.add(Conv2D(filters=512, kernel_size=3, padding='same', activation='relu', trainable=False, name='block4_conv4'))\n",
    "model.add(MaxPooling2D(pool_size=2, name='block4_pool'))\n",
    "\n",
    "#First 1 trainable convnet block\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(filters=512, kernel_size=3, padding='same', activation='relu', trainable=True, name='block5_conv1'))\n",
    "model.add(Conv2D(filters=512, kernel_size=3, padding='same', activation='relu', trainable=True, name='block5_conv2'))\n",
    "model.add(MaxPooling2D(pool_size=2, name='block5_pool'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "#Trainable dense layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Import and assign VGG19 weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "opt = optimizers.rmsprop(lr=0.00005, decay=1e-6)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import applications\n",
    "import h5py\n",
    "\n",
    "weights_path = 'vgg19_weights.h5'\n",
    "f = h5py.File(weights_path, 'r')\n",
    "\n",
    "VGGnet_layers = ['block1_conv1',\n",
    "                 'block1_conv2',\n",
    "                 'block2_conv1',\n",
    "                 'block2_conv2',\n",
    "                 'block3_conv1',\n",
    "                 'block3_conv2',\n",
    "                 'block3_conv3',\n",
    "                 'block3_conv4',\n",
    "                 'block4_conv1',\n",
    "                 'block4_conv2',\n",
    "                 'block4_conv3',\n",
    "                 'block4_conv4']\n",
    "layer_names = [layer.name for layer in model.layers]\n",
    "\n",
    "for i in VGGnet_layers:\n",
    "    weight_names = f[i].attrs[\"weight_names\"]    \n",
    "    weights = [f[i][j] for j in weight_names]\n",
    "    index = layer_names.index(i)\n",
    "    model.layers[index].set_weights(weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2000 samples, validate on 150 samples\n",
      "Epoch 1/20\n",
      "1980/2000 [============================>.] - ETA: 171s - loss: 3.5028 - acc: 0.350 - ETA: 123s - loss: 2.7339 - acc: 0.575 - ETA: 106s - loss: 2.5942 - acc: 0.600 - ETA: 97s - loss: 2.5878 - acc: 0.512 - ETA: 91s - loss: 2.5962 - acc: 0.56 - ETA: 87s - loss: 3.1293 - acc: 0.54 - ETA: 84s - loss: 3.1372 - acc: 0.51 - ETA: 82s - loss: 3.0917 - acc: 0.47 - ETA: 80s - loss: 2.9872 - acc: 0.47 - ETA: 78s - loss: 2.8210 - acc: 0.48 - ETA: 77s - loss: 2.6895 - acc: 0.50 - ETA: 75s - loss: 2.5437 - acc: 0.52 - ETA: 74s - loss: 2.5052 - acc: 0.52 - ETA: 73s - loss: 2.4076 - acc: 0.52 - ETA: 71s - loss: 2.3275 - acc: 0.52 - ETA: 70s - loss: 2.2669 - acc: 0.52 - ETA: 69s - loss: 2.2277 - acc: 0.52 - ETA: 68s - loss: 2.1788 - acc: 0.52 - ETA: 67s - loss: 2.1018 - acc: 0.53 - ETA: 66s - loss: 2.0538 - acc: 0.53 - ETA: 65s - loss: 2.0531 - acc: 0.52 - ETA: 64s - loss: 2.0183 - acc: 0.52 - ETA: 63s - loss: 1.9882 - acc: 0.52 - ETA: 62s - loss: 1.9580 - acc: 0.52 - ETA: 61s - loss: 1.9095 - acc: 0.53 - ETA: 60s - loss: 1.8760 - acc: 0.53 - ETA: 59s - loss: 1.8399 - acc: 0.54 - ETA: 58s - loss: 1.8364 - acc: 0.54 - ETA: 58s - loss: 1.8138 - acc: 0.53 - ETA: 57s - loss: 1.7893 - acc: 0.53 - ETA: 56s - loss: 1.7627 - acc: 0.54 - ETA: 55s - loss: 1.7281 - acc: 0.54 - ETA: 54s - loss: 1.7173 - acc: 0.54 - ETA: 53s - loss: 1.6957 - acc: 0.54 - ETA: 52s - loss: 1.6867 - acc: 0.54 - ETA: 51s - loss: 1.6694 - acc: 0.54 - ETA: 51s - loss: 1.6546 - acc: 0.55 - ETA: 50s - loss: 1.6373 - acc: 0.55 - ETA: 49s - loss: 1.6152 - acc: 0.55 - ETA: 48s - loss: 1.6029 - acc: 0.56 - ETA: 47s - loss: 1.5974 - acc: 0.55 - ETA: 46s - loss: 1.5818 - acc: 0.55 - ETA: 45s - loss: 1.5707 - acc: 0.55 - ETA: 45s - loss: 1.5573 - acc: 0.55 - ETA: 44s - loss: 1.5361 - acc: 0.56 - ETA: 43s - loss: 1.5339 - acc: 0.55 - ETA: 42s - loss: 1.5230 - acc: 0.55 - ETA: 41s - loss: 1.5120 - acc: 0.56 - ETA: 40s - loss: 1.4976 - acc: 0.56 - ETA: 40s - loss: 1.4864 - acc: 0.56 - ETA: 39s - loss: 1.4763 - acc: 0.56 - ETA: 38s - loss: 1.4626 - acc: 0.56 - ETA: 37s - loss: 1.4503 - acc: 0.56 - ETA: 36s - loss: 1.4447 - acc: 0.56 - ETA: 35s - loss: 1.4340 - acc: 0.56 - ETA: 35s - loss: 1.4250 - acc: 0.56 - ETA: 34s - loss: 1.4170 - acc: 0.56 - ETA: 33s - loss: 1.4097 - acc: 0.56 - ETA: 32s - loss: 1.4119 - acc: 0.56 - ETA: 31s - loss: 1.4046 - acc: 0.56 - ETA: 31s - loss: 1.3892 - acc: 0.56 - ETA: 30s - loss: 1.3853 - acc: 0.56 - ETA: 29s - loss: 1.3784 - acc: 0.57 - ETA: 28s - loss: 1.3741 - acc: 0.57 - ETA: 27s - loss: 1.3670 - acc: 0.57 - ETA: 27s - loss: 1.3628 - acc: 0.57 - ETA: 26s - loss: 1.3563 - acc: 0.57 - ETA: 25s - loss: 1.3500 - acc: 0.57 - ETA: 24s - loss: 1.3507 - acc: 0.57 - ETA: 23s - loss: 1.3435 - acc: 0.57 - ETA: 23s - loss: 1.3372 - acc: 0.57 - ETA: 22s - loss: 1.3309 - acc: 0.57 - ETA: 21s - loss: 1.3219 - acc: 0.57 - ETA: 20s - loss: 1.3165 - acc: 0.57 - ETA: 19s - loss: 1.3119 - acc: 0.57 - ETA: 19s - loss: 1.3144 - acc: 0.58 - ETA: 18s - loss: 1.3116 - acc: 0.58 - ETA: 17s - loss: 1.3051 - acc: 0.58 - ETA: 16s - loss: 1.3020 - acc: 0.58 - ETA: 15s - loss: 1.2961 - acc: 0.58 - ETA: 15s - loss: 1.2886 - acc: 0.58 - ETA: 14s - loss: 1.2854 - acc: 0.58 - ETA: 13s - loss: 1.2829 - acc: 0.58 - ETA: 12s - loss: 1.2807 - acc: 0.58 - ETA: 11s - loss: 1.2764 - acc: 0.58 - ETA: 11s - loss: 1.2695 - acc: 0.58 - ETA: 10s - loss: 1.2615 - acc: 0.59 - ETA: 9s - loss: 1.2551 - acc: 0.5920 - ETA: 8s - loss: 1.2500 - acc: 0.594 - ETA: 7s - loss: 1.2441 - acc: 0.596 - ETA: 7s - loss: 1.2442 - acc: 0.596 - ETA: 6s - loss: 1.2411 - acc: 0.596 - ETA: 5s - loss: 1.2363 - acc: 0.596 - ETA: 4s - loss: 1.2302 - acc: 0.597 - ETA: 3s - loss: 1.2256 - acc: 0.597 - ETA: 3s - loss: 1.2206 - acc: 0.599 - ETA: 2s - loss: 1.2178 - acc: 0.600 - ETA: 1s - loss: 1.2119 - acc: 0.601 - ETA: 0s - loss: 1.2096 - acc: 0.6025Epoch 00000: val_loss improved from inf to 1.08661, saving model to saved_models/weights1.hdf5\n",
      "2000/2000 [==============================] - 84s - loss: 1.2061 - acc: 0.6020 - val_loss: 1.0866 - val_acc: 0.5133\n",
      "Epoch 2/20\n",
      "1980/2000 [============================>.] - ETA: 74s - loss: 1.1063 - acc: 0.45 - ETA: 74s - loss: 0.8629 - acc: 0.57 - ETA: 73s - loss: 0.8378 - acc: 0.63 - ETA: 73s - loss: 0.9071 - acc: 0.63 - ETA: 72s - loss: 1.0104 - acc: 0.61 - ETA: 71s - loss: 0.9910 - acc: 0.60 - ETA: 70s - loss: 0.9403 - acc: 0.64 - ETA: 69s - loss: 0.9255 - acc: 0.65 - ETA: 69s - loss: 0.9500 - acc: 0.65 - ETA: 68s - loss: 0.9432 - acc: 0.65 - ETA: 67s - loss: 0.9054 - acc: 0.67 - ETA: 66s - loss: 0.8861 - acc: 0.67 - ETA: 66s - loss: 0.8777 - acc: 0.67 - ETA: 65s - loss: 0.8701 - acc: 0.67 - ETA: 64s - loss: 0.8666 - acc: 0.68 - ETA: 63s - loss: 0.8685 - acc: 0.68 - ETA: 62s - loss: 0.8641 - acc: 0.67 - ETA: 62s - loss: 0.8747 - acc: 0.67 - ETA: 61s - loss: 0.8656 - acc: 0.68 - ETA: 60s - loss: 0.8593 - acc: 0.69 - ETA: 59s - loss: 0.8736 - acc: 0.68 - ETA: 59s - loss: 0.8743 - acc: 0.68 - ETA: 58s - loss: 0.8627 - acc: 0.68 - ETA: 57s - loss: 0.8775 - acc: 0.68 - ETA: 56s - loss: 0.8683 - acc: 0.69 - ETA: 56s - loss: 0.8730 - acc: 0.68 - ETA: 55s - loss: 0.8744 - acc: 0.68 - ETA: 54s - loss: 0.8726 - acc: 0.67 - ETA: 53s - loss: 0.8828 - acc: 0.66 - ETA: 53s - loss: 0.8807 - acc: 0.67 - ETA: 52s - loss: 0.8810 - acc: 0.67 - ETA: 51s - loss: 0.8844 - acc: 0.67 - ETA: 50s - loss: 0.8888 - acc: 0.66 - ETA: 50s - loss: 0.8920 - acc: 0.66 - ETA: 49s - loss: 0.8894 - acc: 0.66 - ETA: 48s - loss: 0.8925 - acc: 0.66 - ETA: 47s - loss: 0.8901 - acc: 0.66 - ETA: 47s - loss: 0.8880 - acc: 0.66 - ETA: 46s - loss: 0.8820 - acc: 0.66 - ETA: 45s - loss: 0.8825 - acc: 0.65 - ETA: 44s - loss: 0.8775 - acc: 0.65 - ETA: 44s - loss: 0.8817 - acc: 0.65 - ETA: 43s - loss: 0.8774 - acc: 0.65 - ETA: 42s - loss: 0.8746 - acc: 0.65 - ETA: 41s - loss: 0.8674 - acc: 0.66 - ETA: 40s - loss: 0.8827 - acc: 0.65 - ETA: 40s - loss: 0.8764 - acc: 0.66 - ETA: 39s - loss: 0.8732 - acc: 0.66 - ETA: 38s - loss: 0.8760 - acc: 0.65 - ETA: 37s - loss: 0.8722 - acc: 0.66 - ETA: 37s - loss: 0.8702 - acc: 0.65 - ETA: 36s - loss: 0.8627 - acc: 0.66 - ETA: 35s - loss: 0.8693 - acc: 0.66 - ETA: 34s - loss: 0.8652 - acc: 0.66 - ETA: 34s - loss: 0.8659 - acc: 0.66 - ETA: 33s - loss: 0.8691 - acc: 0.65 - ETA: 32s - loss: 0.8746 - acc: 0.65 - ETA: 31s - loss: 0.8734 - acc: 0.65 - ETA: 31s - loss: 0.8754 - acc: 0.65 - ETA: 30s - loss: 0.8760 - acc: 0.65 - ETA: 29s - loss: 0.8736 - acc: 0.65 - ETA: 28s - loss: 0.8779 - acc: 0.65 - ETA: 28s - loss: 0.8739 - acc: 0.65 - ETA: 27s - loss: 0.8711 - acc: 0.65 - ETA: 26s - loss: 0.8726 - acc: 0.65 - ETA: 25s - loss: 0.8699 - acc: 0.65 - ETA: 25s - loss: 0.8687 - acc: 0.65 - ETA: 24s - loss: 0.8668 - acc: 0.66 - ETA: 23s - loss: 0.8640 - acc: 0.66 - ETA: 22s - loss: 0.8615 - acc: 0.66 - ETA: 22s - loss: 0.8574 - acc: 0.66 - ETA: 21s - loss: 0.8617 - acc: 0.66 - ETA: 20s - loss: 0.8611 - acc: 0.66 - ETA: 19s - loss: 0.8607 - acc: 0.66 - ETA: 19s - loss: 0.8598 - acc: 0.65 - ETA: 18s - loss: 0.8567 - acc: 0.65 - ETA: 17s - loss: 0.8570 - acc: 0.65 - ETA: 16s - loss: 0.8571 - acc: 0.65 - ETA: 16s - loss: 0.8530 - acc: 0.66 - ETA: 15s - loss: 0.8543 - acc: 0.66 - ETA: 14s - loss: 0.8515 - acc: 0.66 - ETA: 13s - loss: 0.8481 - acc: 0.66 - ETA: 12s - loss: 0.8451 - acc: 0.66 - ETA: 12s - loss: 0.8459 - acc: 0.66 - ETA: 11s - loss: 0.8467 - acc: 0.66 - ETA: 10s - loss: 0.8445 - acc: 0.66 - ETA: 9s - loss: 0.8430 - acc: 0.6655 - ETA: 9s - loss: 0.8390 - acc: 0.668 - ETA: 8s - loss: 0.8366 - acc: 0.669 - ETA: 7s - loss: 0.8383 - acc: 0.669 - ETA: 6s - loss: 0.8357 - acc: 0.670 - ETA: 6s - loss: 0.8302 - acc: 0.672 - ETA: 5s - loss: 0.8343 - acc: 0.672 - ETA: 4s - loss: 0.8336 - acc: 0.671 - ETA: 3s - loss: 0.8319 - acc: 0.673 - ETA: 3s - loss: 0.8317 - acc: 0.673 - ETA: 2s - loss: 0.8296 - acc: 0.674 - ETA: 1s - loss: 0.8291 - acc: 0.673 - ETA: 0s - loss: 0.8278 - acc: 0.6737Epoch 00001: val_loss improved from 1.08661 to 0.87210, saving model to saved_models/weights1.hdf5\n",
      "2000/2000 [==============================] - 81s - loss: 0.8281 - acc: 0.6725 - val_loss: 0.8721 - val_acc: 0.6267\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1980/2000 [============================>.] - ETA: 73s - loss: 0.5114 - acc: 0.80 - ETA: 74s - loss: 0.5636 - acc: 0.80 - ETA: 72s - loss: 0.7199 - acc: 0.75 - ETA: 72s - loss: 0.7604 - acc: 0.71 - ETA: 71s - loss: 0.7981 - acc: 0.70 - ETA: 71s - loss: 0.7718 - acc: 0.70 - ETA: 70s - loss: 0.8101 - acc: 0.67 - ETA: 69s - loss: 0.7930 - acc: 0.67 - ETA: 68s - loss: 0.7875 - acc: 0.67 - ETA: 68s - loss: 0.7689 - acc: 0.68 - ETA: 67s - loss: 0.7632 - acc: 0.68 - ETA: 66s - loss: 0.7612 - acc: 0.67 - ETA: 65s - loss: 0.7408 - acc: 0.68 - ETA: 65s - loss: 0.7308 - acc: 0.68 - ETA: 64s - loss: 0.7274 - acc: 0.69 - ETA: 63s - loss: 0.7326 - acc: 0.68 - ETA: 62s - loss: 0.7190 - acc: 0.69 - ETA: 62s - loss: 0.7218 - acc: 0.68 - ETA: 61s - loss: 0.7180 - acc: 0.69 - ETA: 60s - loss: 0.7169 - acc: 0.69 - ETA: 59s - loss: 0.7136 - acc: 0.69 - ETA: 59s - loss: 0.7105 - acc: 0.70 - ETA: 58s - loss: 0.7068 - acc: 0.70 - ETA: 57s - loss: 0.7160 - acc: 0.70 - ETA: 56s - loss: 0.7112 - acc: 0.70 - ETA: 56s - loss: 0.7099 - acc: 0.70 - ETA: 55s - loss: 0.7143 - acc: 0.70 - ETA: 54s - loss: 0.7116 - acc: 0.71 - ETA: 53s - loss: 0.7088 - acc: 0.71 - ETA: 52s - loss: 0.7173 - acc: 0.71 - ETA: 52s - loss: 0.7185 - acc: 0.70 - ETA: 51s - loss: 0.7115 - acc: 0.71 - ETA: 50s - loss: 0.7089 - acc: 0.71 - ETA: 49s - loss: 0.7087 - acc: 0.71 - ETA: 49s - loss: 0.7003 - acc: 0.71 - ETA: 48s - loss: 0.7019 - acc: 0.71 - ETA: 47s - loss: 0.7067 - acc: 0.71 - ETA: 46s - loss: 0.7065 - acc: 0.71 - ETA: 46s - loss: 0.7058 - acc: 0.71 - ETA: 45s - loss: 0.7082 - acc: 0.71 - ETA: 44s - loss: 0.7116 - acc: 0.71 - ETA: 43s - loss: 0.7115 - acc: 0.71 - ETA: 43s - loss: 0.7114 - acc: 0.71 - ETA: 42s - loss: 0.7122 - acc: 0.71 - ETA: 41s - loss: 0.7116 - acc: 0.70 - ETA: 40s - loss: 0.7162 - acc: 0.70 - ETA: 40s - loss: 0.7121 - acc: 0.71 - ETA: 39s - loss: 0.7194 - acc: 0.70 - ETA: 38s - loss: 0.7227 - acc: 0.70 - ETA: 37s - loss: 0.7194 - acc: 0.70 - ETA: 37s - loss: 0.7145 - acc: 0.70 - ETA: 36s - loss: 0.7152 - acc: 0.70 - ETA: 35s - loss: 0.7184 - acc: 0.70 - ETA: 34s - loss: 0.7208 - acc: 0.69 - ETA: 34s - loss: 0.7209 - acc: 0.69 - ETA: 33s - loss: 0.7243 - acc: 0.69 - ETA: 32s - loss: 0.7245 - acc: 0.69 - ETA: 31s - loss: 0.7230 - acc: 0.69 - ETA: 31s - loss: 0.7180 - acc: 0.69 - ETA: 30s - loss: 0.7183 - acc: 0.69 - ETA: 29s - loss: 0.7231 - acc: 0.69 - ETA: 28s - loss: 0.7229 - acc: 0.69 - ETA: 27s - loss: 0.7198 - acc: 0.69 - ETA: 27s - loss: 0.7203 - acc: 0.69 - ETA: 26s - loss: 0.7251 - acc: 0.69 - ETA: 25s - loss: 0.7264 - acc: 0.69 - ETA: 24s - loss: 0.7244 - acc: 0.69 - ETA: 24s - loss: 0.7261 - acc: 0.69 - ETA: 23s - loss: 0.7265 - acc: 0.69 - ETA: 22s - loss: 0.7295 - acc: 0.69 - ETA: 21s - loss: 0.7256 - acc: 0.69 - ETA: 21s - loss: 0.7223 - acc: 0.70 - ETA: 20s - loss: 0.7191 - acc: 0.70 - ETA: 19s - loss: 0.7190 - acc: 0.70 - ETA: 18s - loss: 0.7191 - acc: 0.70 - ETA: 18s - loss: 0.7192 - acc: 0.70 - ETA: 17s - loss: 0.7181 - acc: 0.70 - ETA: 16s - loss: 0.7188 - acc: 0.70 - ETA: 15s - loss: 0.7198 - acc: 0.70 - ETA: 15s - loss: 0.7184 - acc: 0.70 - ETA: 14s - loss: 0.7219 - acc: 0.70 - ETA: 13s - loss: 0.7228 - acc: 0.69 - ETA: 12s - loss: 0.7245 - acc: 0.69 - ETA: 12s - loss: 0.7268 - acc: 0.69 - ETA: 11s - loss: 0.7273 - acc: 0.69 - ETA: 10s - loss: 0.7236 - acc: 0.69 - ETA: 9s - loss: 0.7264 - acc: 0.6966 - ETA: 9s - loss: 0.7258 - acc: 0.696 - ETA: 8s - loss: 0.7270 - acc: 0.695 - ETA: 7s - loss: 0.7263 - acc: 0.696 - ETA: 6s - loss: 0.7290 - acc: 0.694 - ETA: 6s - loss: 0.7319 - acc: 0.691 - ETA: 5s - loss: 0.7334 - acc: 0.689 - ETA: 4s - loss: 0.7351 - acc: 0.688 - ETA: 3s - loss: 0.7366 - acc: 0.688 - ETA: 3s - loss: 0.7412 - acc: 0.687 - ETA: 2s - loss: 0.7407 - acc: 0.686 - ETA: 1s - loss: 0.7414 - acc: 0.685 - ETA: 0s - loss: 0.7389 - acc: 0.6864Epoch 00002: val_loss improved from 0.87210 to 0.85021, saving model to saved_models/weights1.hdf5\n",
      "2000/2000 [==============================] - 81s - loss: 0.7447 - acc: 0.6840 - val_loss: 0.8502 - val_acc: 0.6267\n",
      "Epoch 4/20\n",
      "1980/2000 [============================>.] - ETA: 74s - loss: 0.5016 - acc: 0.80 - ETA: 74s - loss: 0.5273 - acc: 0.77 - ETA: 73s - loss: 0.6149 - acc: 0.73 - ETA: 72s - loss: 0.5867 - acc: 0.75 - ETA: 71s - loss: 0.6353 - acc: 0.71 - ETA: 71s - loss: 0.6432 - acc: 0.71 - ETA: 70s - loss: 0.7108 - acc: 0.70 - ETA: 69s - loss: 0.6881 - acc: 0.71 - ETA: 68s - loss: 0.7029 - acc: 0.70 - ETA: 68s - loss: 0.6973 - acc: 0.69 - ETA: 67s - loss: 0.6978 - acc: 0.69 - ETA: 66s - loss: 0.6886 - acc: 0.70 - ETA: 65s - loss: 0.6744 - acc: 0.70 - ETA: 65s - loss: 0.6716 - acc: 0.70 - ETA: 64s - loss: 0.6601 - acc: 0.70 - ETA: 63s - loss: 0.6797 - acc: 0.69 - ETA: 62s - loss: 0.6764 - acc: 0.69 - ETA: 61s - loss: 0.6769 - acc: 0.69 - ETA: 61s - loss: 0.6804 - acc: 0.69 - ETA: 60s - loss: 0.6789 - acc: 0.69 - ETA: 59s - loss: 0.6727 - acc: 0.70 - ETA: 59s - loss: 0.6675 - acc: 0.70 - ETA: 58s - loss: 0.6649 - acc: 0.71 - ETA: 57s - loss: 0.6743 - acc: 0.70 - ETA: 56s - loss: 0.6674 - acc: 0.70 - ETA: 56s - loss: 0.6622 - acc: 0.70 - ETA: 55s - loss: 0.6659 - acc: 0.70 - ETA: 54s - loss: 0.6624 - acc: 0.70 - ETA: 53s - loss: 0.6595 - acc: 0.70 - ETA: 53s - loss: 0.6672 - acc: 0.70 - ETA: 52s - loss: 0.6735 - acc: 0.70 - ETA: 51s - loss: 0.6763 - acc: 0.70 - ETA: 50s - loss: 0.6731 - acc: 0.70 - ETA: 51s - loss: 0.6722 - acc: 0.70 - ETA: 50s - loss: 0.6746 - acc: 0.69 - ETA: 49s - loss: 0.6789 - acc: 0.69 - ETA: 49s - loss: 0.6815 - acc: 0.69 - ETA: 48s - loss: 0.6758 - acc: 0.69 - ETA: 47s - loss: 0.6809 - acc: 0.69 - ETA: 46s - loss: 0.6779 - acc: 0.69 - ETA: 45s - loss: 0.6739 - acc: 0.70 - ETA: 45s - loss: 0.6820 - acc: 0.69 - ETA: 44s - loss: 0.6860 - acc: 0.69 - ETA: 43s - loss: 0.6837 - acc: 0.69 - ETA: 42s - loss: 0.6805 - acc: 0.69 - ETA: 41s - loss: 0.6829 - acc: 0.69 - ETA: 41s - loss: 0.6817 - acc: 0.69 - ETA: 40s - loss: 0.6856 - acc: 0.69 - ETA: 39s - loss: 0.6854 - acc: 0.69 - ETA: 38s - loss: 0.6844 - acc: 0.69 - ETA: 37s - loss: 0.6863 - acc: 0.69 - ETA: 37s - loss: 0.6843 - acc: 0.69 - ETA: 36s - loss: 0.6857 - acc: 0.69 - ETA: 35s - loss: 0.6812 - acc: 0.69 - ETA: 34s - loss: 0.6787 - acc: 0.69 - ETA: 33s - loss: 0.6785 - acc: 0.69 - ETA: 33s - loss: 0.6780 - acc: 0.69 - ETA: 32s - loss: 0.6775 - acc: 0.69 - ETA: 31s - loss: 0.6751 - acc: 0.70 - ETA: 30s - loss: 0.6750 - acc: 0.69 - ETA: 30s - loss: 0.6781 - acc: 0.69 - ETA: 29s - loss: 0.6736 - acc: 0.70 - ETA: 28s - loss: 0.6707 - acc: 0.70 - ETA: 27s - loss: 0.6703 - acc: 0.70 - ETA: 26s - loss: 0.6651 - acc: 0.70 - ETA: 26s - loss: 0.6632 - acc: 0.70 - ETA: 25s - loss: 0.6634 - acc: 0.70 - ETA: 24s - loss: 0.6670 - acc: 0.70 - ETA: 23s - loss: 0.6677 - acc: 0.70 - ETA: 23s - loss: 0.6666 - acc: 0.70 - ETA: 22s - loss: 0.6704 - acc: 0.70 - ETA: 21s - loss: 0.6713 - acc: 0.70 - ETA: 20s - loss: 0.6740 - acc: 0.70 - ETA: 19s - loss: 0.6751 - acc: 0.70 - ETA: 19s - loss: 0.6740 - acc: 0.70 - ETA: 18s - loss: 0.6746 - acc: 0.70 - ETA: 17s - loss: 0.6737 - acc: 0.70 - ETA: 16s - loss: 0.6693 - acc: 0.70 - ETA: 16s - loss: 0.6678 - acc: 0.70 - ETA: 15s - loss: 0.6685 - acc: 0.70 - ETA: 14s - loss: 0.6765 - acc: 0.70 - ETA: 13s - loss: 0.6766 - acc: 0.70 - ETA: 13s - loss: 0.6852 - acc: 0.70 - ETA: 12s - loss: 0.6867 - acc: 0.69 - ETA: 11s - loss: 0.6880 - acc: 0.69 - ETA: 10s - loss: 0.6884 - acc: 0.69 - ETA: 9s - loss: 0.6866 - acc: 0.6983 - ETA: 9s - loss: 0.6877 - acc: 0.697 - ETA: 8s - loss: 0.6882 - acc: 0.697 - ETA: 7s - loss: 0.6876 - acc: 0.697 - ETA: 6s - loss: 0.6863 - acc: 0.697 - ETA: 6s - loss: 0.6881 - acc: 0.696 - ETA: 5s - loss: 0.6845 - acc: 0.698 - ETA: 4s - loss: 0.6864 - acc: 0.697 - ETA: 3s - loss: 0.6844 - acc: 0.698 - ETA: 3s - loss: 0.6806 - acc: 0.700 - ETA: 2s - loss: 0.6840 - acc: 0.699 - ETA: 1s - loss: 0.6869 - acc: 0.696 - ETA: 0s - loss: 0.6862 - acc: 0.6970Epoch 00003: val_loss improved from 0.85021 to 0.83922, saving model to saved_models/weights1.hdf5\n",
      "2000/2000 [==============================] - 81s - loss: 0.6845 - acc: 0.6975 - val_loss: 0.8392 - val_acc: 0.5800\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1980/2000 [============================>.] - ETA: 74s - loss: 0.6512 - acc: 0.65 - ETA: 73s - loss: 0.7473 - acc: 0.60 - ETA: 73s - loss: 0.7147 - acc: 0.65 - ETA: 72s - loss: 0.6729 - acc: 0.67 - ETA: 71s - loss: 0.6829 - acc: 0.67 - ETA: 71s - loss: 0.6896 - acc: 0.68 - ETA: 70s - loss: 0.6926 - acc: 0.67 - ETA: 69s - loss: 0.6476 - acc: 0.70 - ETA: 69s - loss: 0.6562 - acc: 0.69 - ETA: 68s - loss: 0.6536 - acc: 0.70 - ETA: 67s - loss: 0.6471 - acc: 0.70 - ETA: 66s - loss: 0.6288 - acc: 0.71 - ETA: 65s - loss: 0.6575 - acc: 0.70 - ETA: 65s - loss: 0.6480 - acc: 0.71 - ETA: 64s - loss: 0.6255 - acc: 0.72 - ETA: 63s - loss: 0.6272 - acc: 0.72 - ETA: 62s - loss: 0.6133 - acc: 0.73 - ETA: 61s - loss: 0.6123 - acc: 0.73 - ETA: 61s - loss: 0.6319 - acc: 0.72 - ETA: 60s - loss: 0.6443 - acc: 0.72 - ETA: 59s - loss: 0.6368 - acc: 0.72 - ETA: 58s - loss: 0.6411 - acc: 0.72 - ETA: 58s - loss: 0.6468 - acc: 0.71 - ETA: 57s - loss: 0.6391 - acc: 0.72 - ETA: 56s - loss: 0.6376 - acc: 0.72 - ETA: 55s - loss: 0.6457 - acc: 0.72 - ETA: 55s - loss: 0.6462 - acc: 0.72 - ETA: 54s - loss: 0.6430 - acc: 0.72 - ETA: 53s - loss: 0.6449 - acc: 0.72 - ETA: 52s - loss: 0.6441 - acc: 0.72 - ETA: 52s - loss: 0.6431 - acc: 0.72 - ETA: 51s - loss: 0.6403 - acc: 0.72 - ETA: 50s - loss: 0.6376 - acc: 0.72 - ETA: 49s - loss: 0.6369 - acc: 0.72 - ETA: 49s - loss: 0.6424 - acc: 0.71 - ETA: 48s - loss: 0.6431 - acc: 0.71 - ETA: 47s - loss: 0.6409 - acc: 0.71 - ETA: 46s - loss: 0.6375 - acc: 0.71 - ETA: 46s - loss: 0.6361 - acc: 0.71 - ETA: 45s - loss: 0.6295 - acc: 0.71 - ETA: 44s - loss: 0.6275 - acc: 0.71 - ETA: 43s - loss: 0.6260 - acc: 0.72 - ETA: 43s - loss: 0.6249 - acc: 0.72 - ETA: 42s - loss: 0.6270 - acc: 0.71 - ETA: 41s - loss: 0.6258 - acc: 0.72 - ETA: 40s - loss: 0.6208 - acc: 0.72 - ETA: 40s - loss: 0.6234 - acc: 0.72 - ETA: 39s - loss: 0.6222 - acc: 0.72 - ETA: 38s - loss: 0.6219 - acc: 0.72 - ETA: 37s - loss: 0.6238 - acc: 0.72 - ETA: 37s - loss: 0.6240 - acc: 0.72 - ETA: 36s - loss: 0.6199 - acc: 0.73 - ETA: 35s - loss: 0.6167 - acc: 0.73 - ETA: 34s - loss: 0.6201 - acc: 0.72 - ETA: 34s - loss: 0.6206 - acc: 0.73 - ETA: 33s - loss: 0.6204 - acc: 0.73 - ETA: 32s - loss: 0.6173 - acc: 0.73 - ETA: 31s - loss: 0.6188 - acc: 0.73 - ETA: 31s - loss: 0.6207 - acc: 0.72 - ETA: 30s - loss: 0.6197 - acc: 0.72 - ETA: 29s - loss: 0.6201 - acc: 0.73 - ETA: 28s - loss: 0.6199 - acc: 0.73 - ETA: 27s - loss: 0.6187 - acc: 0.73 - ETA: 27s - loss: 0.6195 - acc: 0.73 - ETA: 26s - loss: 0.6208 - acc: 0.73 - ETA: 25s - loss: 0.6178 - acc: 0.73 - ETA: 24s - loss: 0.6168 - acc: 0.73 - ETA: 24s - loss: 0.6195 - acc: 0.73 - ETA: 23s - loss: 0.6178 - acc: 0.73 - ETA: 22s - loss: 0.6161 - acc: 0.73 - ETA: 21s - loss: 0.6160 - acc: 0.73 - ETA: 21s - loss: 0.6162 - acc: 0.73 - ETA: 20s - loss: 0.6149 - acc: 0.73 - ETA: 19s - loss: 0.6158 - acc: 0.73 - ETA: 18s - loss: 0.6150 - acc: 0.73 - ETA: 18s - loss: 0.6182 - acc: 0.73 - ETA: 17s - loss: 0.6195 - acc: 0.73 - ETA: 16s - loss: 0.6186 - acc: 0.73 - ETA: 15s - loss: 0.6217 - acc: 0.72 - ETA: 15s - loss: 0.6241 - acc: 0.72 - ETA: 14s - loss: 0.6256 - acc: 0.72 - ETA: 13s - loss: 0.6265 - acc: 0.72 - ETA: 12s - loss: 0.6282 - acc: 0.72 - ETA: 12s - loss: 0.6265 - acc: 0.72 - ETA: 11s - loss: 0.6235 - acc: 0.72 - ETA: 10s - loss: 0.6224 - acc: 0.72 - ETA: 9s - loss: 0.6187 - acc: 0.7310 - ETA: 9s - loss: 0.6238 - acc: 0.727 - ETA: 8s - loss: 0.6249 - acc: 0.725 - ETA: 7s - loss: 0.6244 - acc: 0.726 - ETA: 6s - loss: 0.6271 - acc: 0.724 - ETA: 6s - loss: 0.6270 - acc: 0.725 - ETA: 5s - loss: 0.6274 - acc: 0.725 - ETA: 4s - loss: 0.6253 - acc: 0.726 - ETA: 3s - loss: 0.6249 - acc: 0.726 - ETA: 3s - loss: 0.6226 - acc: 0.728 - ETA: 2s - loss: 0.6198 - acc: 0.728 - ETA: 1s - loss: 0.6227 - acc: 0.727 - ETA: 0s - loss: 0.6223 - acc: 0.7283Epoch 00004: val_loss improved from 0.83922 to 0.75999, saving model to saved_models/weights1.hdf5\n",
      "2000/2000 [==============================] - 80s - loss: 0.6231 - acc: 0.7280 - val_loss: 0.7600 - val_acc: 0.6600\n",
      "Epoch 6/20\n",
      "1980/2000 [============================>.] - ETA: 74s - loss: 0.7848 - acc: 0.70 - ETA: 73s - loss: 0.7195 - acc: 0.70 - ETA: 72s - loss: 0.7484 - acc: 0.68 - ETA: 72s - loss: 0.7451 - acc: 0.68 - ETA: 71s - loss: 0.6684 - acc: 0.72 - ETA: 70s - loss: 0.6470 - acc: 0.73 - ETA: 70s - loss: 0.6568 - acc: 0.72 - ETA: 69s - loss: 0.6612 - acc: 0.71 - ETA: 68s - loss: 0.6838 - acc: 0.70 - ETA: 68s - loss: 0.6639 - acc: 0.70 - ETA: 67s - loss: 0.6608 - acc: 0.71 - ETA: 66s - loss: 0.6459 - acc: 0.72 - ETA: 65s - loss: 0.6322 - acc: 0.72 - ETA: 65s - loss: 0.6509 - acc: 0.71 - ETA: 64s - loss: 0.6292 - acc: 0.73 - ETA: 63s - loss: 0.6126 - acc: 0.74 - ETA: 62s - loss: 0.6145 - acc: 0.73 - ETA: 62s - loss: 0.6114 - acc: 0.73 - ETA: 61s - loss: 0.6184 - acc: 0.73 - ETA: 60s - loss: 0.6115 - acc: 0.73 - ETA: 59s - loss: 0.6033 - acc: 0.74 - ETA: 59s - loss: 0.5922 - acc: 0.74 - ETA: 58s - loss: 0.5836 - acc: 0.75 - ETA: 58s - loss: 0.5996 - acc: 0.74 - ETA: 57s - loss: 0.6013 - acc: 0.74 - ETA: 56s - loss: 0.5921 - acc: 0.75 - ETA: 55s - loss: 0.5945 - acc: 0.74 - ETA: 55s - loss: 0.5948 - acc: 0.74 - ETA: 54s - loss: 0.5961 - acc: 0.74 - ETA: 53s - loss: 0.5964 - acc: 0.74 - ETA: 52s - loss: 0.5966 - acc: 0.74 - ETA: 51s - loss: 0.6096 - acc: 0.73 - ETA: 51s - loss: 0.6120 - acc: 0.73 - ETA: 50s - loss: 0.6106 - acc: 0.73 - ETA: 49s - loss: 0.6186 - acc: 0.73 - ETA: 48s - loss: 0.6183 - acc: 0.73 - ETA: 48s - loss: 0.6186 - acc: 0.73 - ETA: 47s - loss: 0.6164 - acc: 0.73 - ETA: 46s - loss: 0.6125 - acc: 0.73 - ETA: 45s - loss: 0.6176 - acc: 0.73 - ETA: 44s - loss: 0.6113 - acc: 0.74 - ETA: 44s - loss: 0.6097 - acc: 0.74 - ETA: 43s - loss: 0.6101 - acc: 0.74 - ETA: 42s - loss: 0.6071 - acc: 0.74 - ETA: 41s - loss: 0.6050 - acc: 0.74 - ETA: 41s - loss: 0.6130 - acc: 0.74 - ETA: 40s - loss: 0.6219 - acc: 0.73 - ETA: 39s - loss: 0.6160 - acc: 0.74 - ETA: 39s - loss: 0.6149 - acc: 0.74 - ETA: 39s - loss: 0.6120 - acc: 0.74 - ETA: 38s - loss: 0.6137 - acc: 0.74 - ETA: 37s - loss: 0.6138 - acc: 0.74 - ETA: 36s - loss: 0.6119 - acc: 0.74 - ETA: 35s - loss: 0.6091 - acc: 0.74 - ETA: 35s - loss: 0.6103 - acc: 0.74 - ETA: 34s - loss: 0.6109 - acc: 0.74 - ETA: 33s - loss: 0.6131 - acc: 0.74 - ETA: 32s - loss: 0.6147 - acc: 0.74 - ETA: 31s - loss: 0.6183 - acc: 0.73 - ETA: 31s - loss: 0.6179 - acc: 0.73 - ETA: 30s - loss: 0.6140 - acc: 0.73 - ETA: 29s - loss: 0.6083 - acc: 0.74 - ETA: 28s - loss: 0.6072 - acc: 0.74 - ETA: 27s - loss: 0.6006 - acc: 0.74 - ETA: 27s - loss: 0.6035 - acc: 0.74 - ETA: 26s - loss: 0.6044 - acc: 0.74 - ETA: 25s - loss: 0.6034 - acc: 0.74 - ETA: 24s - loss: 0.6005 - acc: 0.74 - ETA: 24s - loss: 0.5983 - acc: 0.74 - ETA: 23s - loss: 0.5972 - acc: 0.74 - ETA: 22s - loss: 0.6003 - acc: 0.74 - ETA: 21s - loss: 0.5982 - acc: 0.74 - ETA: 20s - loss: 0.5970 - acc: 0.74 - ETA: 20s - loss: 0.5985 - acc: 0.74 - ETA: 19s - loss: 0.5978 - acc: 0.74 - ETA: 18s - loss: 0.5978 - acc: 0.74 - ETA: 17s - loss: 0.5950 - acc: 0.74 - ETA: 16s - loss: 0.5939 - acc: 0.74 - ETA: 16s - loss: 0.5926 - acc: 0.74 - ETA: 15s - loss: 0.5921 - acc: 0.74 - ETA: 14s - loss: 0.5900 - acc: 0.75 - ETA: 13s - loss: 0.5900 - acc: 0.75 - ETA: 13s - loss: 0.5905 - acc: 0.74 - ETA: 12s - loss: 0.5896 - acc: 0.74 - ETA: 11s - loss: 0.5899 - acc: 0.74 - ETA: 10s - loss: 0.5904 - acc: 0.74 - ETA: 10s - loss: 0.5911 - acc: 0.74 - ETA: 9s - loss: 0.5890 - acc: 0.7472 - ETA: 8s - loss: 0.5903 - acc: 0.746 - ETA: 7s - loss: 0.5881 - acc: 0.747 - ETA: 6s - loss: 0.5867 - acc: 0.747 - ETA: 6s - loss: 0.5843 - acc: 0.748 - ETA: 5s - loss: 0.5841 - acc: 0.747 - ETA: 4s - loss: 0.5820 - acc: 0.748 - ETA: 3s - loss: 0.5821 - acc: 0.748 - ETA: 3s - loss: 0.5840 - acc: 0.747 - ETA: 2s - loss: 0.5831 - acc: 0.746 - ETA: 1s - loss: 0.5816 - acc: 0.747 - ETA: 0s - loss: 0.5821 - acc: 0.7475Epoch 00005: val_loss did not improve\n",
      "2000/2000 [==============================] - 82s - loss: 0.5853 - acc: 0.7475 - val_loss: 0.7635 - val_acc: 0.6800\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1980/2000 [============================>.] - ETA: 74s - loss: 0.5213 - acc: 0.75 - ETA: 73s - loss: 0.4764 - acc: 0.80 - ETA: 72s - loss: 0.5483 - acc: 0.73 - ETA: 71s - loss: 0.5697 - acc: 0.73 - ETA: 71s - loss: 0.5648 - acc: 0.74 - ETA: 70s - loss: 0.5664 - acc: 0.74 - ETA: 69s - loss: 0.5427 - acc: 0.76 - ETA: 69s - loss: 0.5547 - acc: 0.76 - ETA: 68s - loss: 0.5704 - acc: 0.76 - ETA: 67s - loss: 0.5935 - acc: 0.75 - ETA: 66s - loss: 0.5857 - acc: 0.76 - ETA: 66s - loss: 0.5793 - acc: 0.77 - ETA: 65s - loss: 0.5910 - acc: 0.76 - ETA: 64s - loss: 0.5809 - acc: 0.77 - ETA: 64s - loss: 0.5774 - acc: 0.77 - ETA: 63s - loss: 0.5515 - acc: 0.78 - ETA: 62s - loss: 0.5498 - acc: 0.78 - ETA: 61s - loss: 0.5639 - acc: 0.77 - ETA: 61s - loss: 0.5594 - acc: 0.77 - ETA: 60s - loss: 0.5508 - acc: 0.78 - ETA: 59s - loss: 0.5489 - acc: 0.78 - ETA: 58s - loss: 0.5440 - acc: 0.78 - ETA: 58s - loss: 0.5537 - acc: 0.78 - ETA: 57s - loss: 0.5477 - acc: 0.78 - ETA: 56s - loss: 0.5599 - acc: 0.77 - ETA: 55s - loss: 0.5562 - acc: 0.77 - ETA: 55s - loss: 0.5578 - acc: 0.77 - ETA: 54s - loss: 0.5486 - acc: 0.77 - ETA: 53s - loss: 0.5437 - acc: 0.77 - ETA: 52s - loss: 0.5532 - acc: 0.76 - ETA: 52s - loss: 0.5531 - acc: 0.76 - ETA: 51s - loss: 0.5480 - acc: 0.77 - ETA: 50s - loss: 0.5382 - acc: 0.77 - ETA: 49s - loss: 0.5384 - acc: 0.77 - ETA: 49s - loss: 0.5389 - acc: 0.77 - ETA: 48s - loss: 0.5346 - acc: 0.77 - ETA: 47s - loss: 0.5336 - acc: 0.77 - ETA: 46s - loss: 0.5350 - acc: 0.77 - ETA: 46s - loss: 0.5374 - acc: 0.76 - ETA: 45s - loss: 0.5392 - acc: 0.76 - ETA: 44s - loss: 0.5398 - acc: 0.76 - ETA: 43s - loss: 0.5396 - acc: 0.77 - ETA: 43s - loss: 0.5441 - acc: 0.76 - ETA: 42s - loss: 0.5438 - acc: 0.76 - ETA: 41s - loss: 0.5441 - acc: 0.76 - ETA: 40s - loss: 0.5450 - acc: 0.76 - ETA: 39s - loss: 0.5394 - acc: 0.76 - ETA: 39s - loss: 0.5446 - acc: 0.76 - ETA: 38s - loss: 0.5451 - acc: 0.76 - ETA: 37s - loss: 0.5445 - acc: 0.76 - ETA: 36s - loss: 0.5453 - acc: 0.76 - ETA: 36s - loss: 0.5450 - acc: 0.76 - ETA: 35s - loss: 0.5407 - acc: 0.76 - ETA: 34s - loss: 0.5426 - acc: 0.76 - ETA: 33s - loss: 0.5404 - acc: 0.76 - ETA: 33s - loss: 0.5371 - acc: 0.76 - ETA: 32s - loss: 0.5407 - acc: 0.76 - ETA: 31s - loss: 0.5373 - acc: 0.76 - ETA: 30s - loss: 0.5413 - acc: 0.76 - ETA: 30s - loss: 0.5424 - acc: 0.76 - ETA: 29s - loss: 0.5456 - acc: 0.76 - ETA: 28s - loss: 0.5488 - acc: 0.76 - ETA: 27s - loss: 0.5468 - acc: 0.76 - ETA: 27s - loss: 0.5441 - acc: 0.76 - ETA: 26s - loss: 0.5423 - acc: 0.76 - ETA: 25s - loss: 0.5415 - acc: 0.76 - ETA: 24s - loss: 0.5400 - acc: 0.76 - ETA: 24s - loss: 0.5384 - acc: 0.76 - ETA: 23s - loss: 0.5395 - acc: 0.76 - ETA: 22s - loss: 0.5453 - acc: 0.76 - ETA: 21s - loss: 0.5445 - acc: 0.76 - ETA: 21s - loss: 0.5444 - acc: 0.76 - ETA: 20s - loss: 0.5452 - acc: 0.76 - ETA: 19s - loss: 0.5435 - acc: 0.76 - ETA: 18s - loss: 0.5410 - acc: 0.76 - ETA: 18s - loss: 0.5428 - acc: 0.76 - ETA: 17s - loss: 0.5402 - acc: 0.76 - ETA: 16s - loss: 0.5418 - acc: 0.76 - ETA: 15s - loss: 0.5417 - acc: 0.76 - ETA: 15s - loss: 0.5384 - acc: 0.76 - ETA: 14s - loss: 0.5435 - acc: 0.76 - ETA: 13s - loss: 0.5443 - acc: 0.76 - ETA: 12s - loss: 0.5443 - acc: 0.76 - ETA: 12s - loss: 0.5428 - acc: 0.76 - ETA: 11s - loss: 0.5449 - acc: 0.76 - ETA: 10s - loss: 0.5429 - acc: 0.76 - ETA: 9s - loss: 0.5429 - acc: 0.7655 - ETA: 9s - loss: 0.5427 - acc: 0.765 - ETA: 8s - loss: 0.5440 - acc: 0.764 - ETA: 7s - loss: 0.5434 - acc: 0.765 - ETA: 6s - loss: 0.5415 - acc: 0.765 - ETA: 6s - loss: 0.5461 - acc: 0.765 - ETA: 5s - loss: 0.5452 - acc: 0.766 - ETA: 4s - loss: 0.5438 - acc: 0.767 - ETA: 3s - loss: 0.5432 - acc: 0.767 - ETA: 3s - loss: 0.5423 - acc: 0.767 - ETA: 2s - loss: 0.5460 - acc: 0.764 - ETA: 1s - loss: 0.5459 - acc: 0.764 - ETA: 0s - loss: 0.5444 - acc: 0.7652Epoch 00006: val_loss improved from 0.75999 to 0.71913, saving model to saved_models/weights1.hdf5\n",
      "2000/2000 [==============================] - 81s - loss: 0.5453 - acc: 0.7645 - val_loss: 0.7191 - val_acc: 0.6800\n",
      "Epoch 8/20\n",
      "1980/2000 [============================>.] - ETA: 74s - loss: 0.5579 - acc: 0.75 - ETA: 73s - loss: 0.4890 - acc: 0.77 - ETA: 73s - loss: 0.4717 - acc: 0.78 - ETA: 72s - loss: 0.4420 - acc: 0.81 - ETA: 72s - loss: 0.4525 - acc: 0.80 - ETA: 71s - loss: 0.5033 - acc: 0.78 - ETA: 70s - loss: 0.5297 - acc: 0.76 - ETA: 69s - loss: 0.5760 - acc: 0.73 - ETA: 69s - loss: 0.5773 - acc: 0.75 - ETA: 68s - loss: 0.5387 - acc: 0.77 - ETA: 67s - loss: 0.5424 - acc: 0.76 - ETA: 66s - loss: 0.5475 - acc: 0.75 - ETA: 66s - loss: 0.5482 - acc: 0.74 - ETA: 65s - loss: 0.5284 - acc: 0.76 - ETA: 64s - loss: 0.5142 - acc: 0.77 - ETA: 63s - loss: 0.5248 - acc: 0.76 - ETA: 63s - loss: 0.5265 - acc: 0.77 - ETA: 62s - loss: 0.5580 - acc: 0.77 - ETA: 61s - loss: 0.5627 - acc: 0.76 - ETA: 60s - loss: 0.5673 - acc: 0.76 - ETA: 59s - loss: 0.5577 - acc: 0.76 - ETA: 59s - loss: 0.5637 - acc: 0.76 - ETA: 58s - loss: 0.5671 - acc: 0.76 - ETA: 57s - loss: 0.5654 - acc: 0.76 - ETA: 56s - loss: 0.5551 - acc: 0.77 - ETA: 56s - loss: 0.5541 - acc: 0.76 - ETA: 55s - loss: 0.5493 - acc: 0.77 - ETA: 54s - loss: 0.5408 - acc: 0.77 - ETA: 53s - loss: 0.5416 - acc: 0.77 - ETA: 53s - loss: 0.5329 - acc: 0.78 - ETA: 52s - loss: 0.5299 - acc: 0.78 - ETA: 51s - loss: 0.5304 - acc: 0.78 - ETA: 50s - loss: 0.5295 - acc: 0.78 - ETA: 50s - loss: 0.5309 - acc: 0.78 - ETA: 49s - loss: 0.5242 - acc: 0.78 - ETA: 48s - loss: 0.5225 - acc: 0.78 - ETA: 47s - loss: 0.5172 - acc: 0.78 - ETA: 47s - loss: 0.5132 - acc: 0.78 - ETA: 46s - loss: 0.5122 - acc: 0.78 - ETA: 45s - loss: 0.5171 - acc: 0.78 - ETA: 44s - loss: 0.5190 - acc: 0.78 - ETA: 44s - loss: 0.5188 - acc: 0.78 - ETA: 43s - loss: 0.5214 - acc: 0.78 - ETA: 42s - loss: 0.5223 - acc: 0.78 - ETA: 41s - loss: 0.5196 - acc: 0.78 - ETA: 41s - loss: 0.5213 - acc: 0.78 - ETA: 40s - loss: 0.5202 - acc: 0.77 - ETA: 39s - loss: 0.5191 - acc: 0.78 - ETA: 38s - loss: 0.5179 - acc: 0.78 - ETA: 37s - loss: 0.5182 - acc: 0.78 - ETA: 37s - loss: 0.5153 - acc: 0.78 - ETA: 36s - loss: 0.5118 - acc: 0.78 - ETA: 35s - loss: 0.5095 - acc: 0.78 - ETA: 34s - loss: 0.5092 - acc: 0.78 - ETA: 34s - loss: 0.5129 - acc: 0.78 - ETA: 33s - loss: 0.5110 - acc: 0.78 - ETA: 32s - loss: 0.5090 - acc: 0.78 - ETA: 31s - loss: 0.5108 - acc: 0.78 - ETA: 31s - loss: 0.5123 - acc: 0.78 - ETA: 30s - loss: 0.5089 - acc: 0.78 - ETA: 30s - loss: 0.5072 - acc: 0.78 - ETA: 29s - loss: 0.5036 - acc: 0.79 - ETA: 28s - loss: 0.5044 - acc: 0.78 - ETA: 27s - loss: 0.5028 - acc: 0.79 - ETA: 26s - loss: 0.5012 - acc: 0.79 - ETA: 26s - loss: 0.4980 - acc: 0.79 - ETA: 25s - loss: 0.5059 - acc: 0.78 - ETA: 24s - loss: 0.5123 - acc: 0.78 - ETA: 23s - loss: 0.5129 - acc: 0.78 - ETA: 23s - loss: 0.5130 - acc: 0.78 - ETA: 22s - loss: 0.5122 - acc: 0.78 - ETA: 21s - loss: 0.5119 - acc: 0.78 - ETA: 20s - loss: 0.5135 - acc: 0.78 - ETA: 19s - loss: 0.5127 - acc: 0.78 - ETA: 19s - loss: 0.5130 - acc: 0.78 - ETA: 18s - loss: 0.5154 - acc: 0.78 - ETA: 17s - loss: 0.5151 - acc: 0.78 - ETA: 16s - loss: 0.5148 - acc: 0.78 - ETA: 16s - loss: 0.5119 - acc: 0.78 - ETA: 15s - loss: 0.5124 - acc: 0.78 - ETA: 14s - loss: 0.5158 - acc: 0.78 - ETA: 13s - loss: 0.5174 - acc: 0.77 - ETA: 13s - loss: 0.5153 - acc: 0.78 - ETA: 12s - loss: 0.5125 - acc: 0.78 - ETA: 11s - loss: 0.5108 - acc: 0.78 - ETA: 10s - loss: 0.5092 - acc: 0.78 - ETA: 9s - loss: 0.5082 - acc: 0.7828 - ETA: 9s - loss: 0.5085 - acc: 0.782 - ETA: 8s - loss: 0.5072 - acc: 0.783 - ETA: 7s - loss: 0.5085 - acc: 0.782 - ETA: 6s - loss: 0.5081 - acc: 0.782 - ETA: 6s - loss: 0.5105 - acc: 0.779 - ETA: 5s - loss: 0.5141 - acc: 0.779 - ETA: 4s - loss: 0.5142 - acc: 0.779 - ETA: 3s - loss: 0.5182 - acc: 0.776 - ETA: 3s - loss: 0.5171 - acc: 0.777 - ETA: 2s - loss: 0.5149 - acc: 0.778 - ETA: 1s - loss: 0.5162 - acc: 0.778 - ETA: 0s - loss: 0.5165 - acc: 0.7778"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint  \n",
    "\n",
    "epochs = 20\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights1.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "model.fit(train_tensors, train_labels,\n",
    "            validation_data=(valid_tensors, valid_labels),\n",
    "            epochs=epochs,\n",
    "            batch_size=20,\n",
    "            callbacks=[checkpointer],\n",
    "            verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create output .csv for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the model weights with the best validation loss.\n",
    "\n",
    "model.load_weights('saved_models/weights1.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "prediction = np.argmax(model.predict(np.expand_dims(test_tensors[0], axis=0)))\n",
    "print(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 600/600 [00:11<00:00, 51.09it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "y_pred = pd.DataFrame(columns=[\"task_1\", \"task_2\"])\n",
    "\n",
    "for ii in tqdm(range(len(test_files))):\n",
    "    path = test_files[ii]\n",
    "    prediction = np.argmax(model.predict(np.expand_dims(test_tensors[ii], axis=0)))\n",
    "    if prediction == 0:\n",
    "        y_pred.loc[path] = [1, 0]\n",
    "    if prediction == 2:\n",
    "        y_pred.loc[path] = [0, 1]\n",
    "    else:\n",
    "        y_pred.loc[path] = [0, 0]\n",
    "\n",
    "y_pred.to_csv(\"predictions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Internal testing vs. ground truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def plot_roc_auc(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    This function plots the ROC curves and provides the scores.\n",
    "    \"\"\"\n",
    "\n",
    "    # initialize dictionaries and array\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = np.zeros(3)\n",
    "    \n",
    "    # prepare for figure\n",
    "    plt.figure()\n",
    "    colors = ['aqua', 'cornflowerblue']\n",
    "\n",
    "    # for both classification tasks (categories 1 and 2)\n",
    "    for i in range(2):\n",
    "        # obtain ROC curve\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_true[:,i], y_pred[:,i])\n",
    "        # obtain ROC AUC\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "        # plot ROC curve\n",
    "        plt.plot(fpr[i], tpr[i], color=colors[i], lw=2,\n",
    "                 label='ROC curve for task {d} (area = {f:.2f})'.format(d=i+1, f=roc_auc[i]))\n",
    "    # get score for category 3\n",
    "    roc_auc[2] = np.average(roc_auc[:2])\n",
    "    \n",
    "    # format figure\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC curves')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    \n",
    "    # print scores\n",
    "    for i in range(3):\n",
    "        print('Category {d} Score: {f:.3f}'. format(d=i+1, f=roc_auc[i]))\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, thresh, classes):\n",
    "    \"\"\"\n",
    "    This function plots the (normalized) confusion matrix.\n",
    "    \"\"\"\n",
    "\n",
    "    # obtain class predictions from probabilities\n",
    "    y_pred = (y_pred>=thresh)*1\n",
    "    # obtain (unnormalized) confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # normalize confusion matrix\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion matrix')\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], '.2f'),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnHNZeaFwzjmXlRcK55xzWf0f4lxT1iCHrM4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26050b49438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category 1 Score: 0.500\n",
      "Category 2 Score: 0.658\n",
      "Category 3 Score: 0.579\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVMAAAEmCAYAAADfpHMGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x260503e7f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds_path = sys.argv[1]\n",
    "thresh = 0.5\n",
    "\n",
    "# get ground truth labels for test dataset\n",
    "truth = pd.read_csv('ground_truth.csv')\n",
    "y_true = truth.as_matrix(columns=[\"task_1\", \"task_2\"])\n",
    "\n",
    "# get model predictions for test dataset\n",
    "y_pred = pd.read_csv(\"predictions.csv\")\n",
    "y_pred = y_pred.as_matrix(columns=[\"task_1\", \"task_2\"])\n",
    "\n",
    "# plot ROC curves and print scores\n",
    "plot_roc_auc(y_true, y_pred)\n",
    "# plot confusion matrix\n",
    "classes = ['benign', 'malignant']\n",
    "plot_confusion_matrix(y_true[:,0], y_pred[:,0], thresh, classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
